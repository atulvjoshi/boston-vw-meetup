{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter optimization with Vowpal Wabbit and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "1. Docker is awesome: \n",
    "    * https://docs.docker.com/mac/started/\n",
    "2. Edit your virtual machine settings (may need to power off default vm)\n",
    "    * System - add memory and processors\n",
    "    * Network -> Port Forwarding\n",
    "        * add entry - Name: jupyter, Protocol: TCP, Host IP: 127.0.0.1, Host Port: 8888, Guest Port: 8888\n",
    "3. Start up a docker session\n",
    "    * Docker Quick Start Terminal\n",
    "3. Check out ML-Toolbox: \n",
    "    * git clone https://github.com/gramhagen/ml-toolbox\n",
    "4. Start the notebook server:\n",
    "    * docker-compose up -d\n",
    "5. Open the Jupyter Notebook\n",
    "    * open http://localhost:8888\n",
    "    \n",
    "### Cleanup\n",
    "1. Stop the notebook server:\n",
    "    * docker-compose stop\n",
    "2. Power off the vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle\n",
    "\n",
    "with open('/notebook/data/n_features.pkl', 'r') as f:\n",
    "    n_features = pickle.load(f)\n",
    "    \n",
    "feature_file = '/notebook/data/train-0.1m.svm'\n",
    "\n",
    "X, y = load_svmlight_file(feature_file, n_features=n_features)\n",
    "# convert to labels from 0.0, 1.0 to -1, 1\n",
    "y = (y.astype(int) * 2 - 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.05, test_size=0.1, random_state=42)\n",
    "X_tune, X_test, y_tune, y_test = train_test_split(X_test, y_test, train_size=0.5, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla VW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.507892943671\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn_vw import VWClassifier\n",
    "\n",
    "model = VWClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print 'AUC: {}'.format(metrics.roc_auc_score(y_tune, model.predict(X_tune)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 11.46 seconds for 9 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.656 (std: 0.017)\n",
      "Parameters: {'power_t': 0, 'l': 1.0}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.619 (std: 0.007)\n",
      "Parameters: {'power_t': 0.5, 'l': 1.0}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.611 (std: 0.023)\n",
      "Parameters: {'power_t': 0, 'l': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "        \n",
    "# create parameter grid\n",
    "params = {\"l\": [0.1, 1.0, 10],\n",
    "          \"power_t\": [0, 0.5, 1.0]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(VWClassifier(), \n",
    "                           param_grid=params, \n",
    "                           scoring='roc_auc')\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.549069587455\n"
     ]
    }
   ],
   "source": [
    "model = VWClassifier(power_t=0, l=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print 'AUC: {}'.format(metrics.roc_auc_score(y_tune, model.predict(X_tune)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats.distributions import uniform\n",
    "\n",
    "\n",
    "# create parameter ranges\n",
    "np.random.seed(1)\n",
    "n_iter = 9\n",
    "params = {\"l\": uniform(0.01, 10),\n",
    "          \"power_t\": uniform()}\n",
    "\n",
    "# run search\n",
    "search = RandomizedSearchCV(VWClassifier(), \n",
    "                            param_distributions=params, \n",
    "                            scoring='roc_auc',\n",
    "                            n_iter=n_iter)\n",
    "start = time()\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Parameter search took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(search.grid_scores_)))\n",
    "report(search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.55413596137\n"
     ]
    }
   ],
   "source": [
    "model = VWClassifier(power_t=0.09, l=1.48)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print 'AUC: {}'.format(metrics.roc_auc_score(y_tune, model.predict(X_tune)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Evolutionary Search\n",
    "https://github.com/rsteca/sklearn-deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from scipy.stats.distributions import uniform\n",
    "\n",
    "# create parameter grid\n",
    "params = {\"l\": [0.1, 1.0, 10],\n",
    "          \"power_t\": [0, 0.5, 1.0]}\n",
    "\n",
    "search = EvolutionaryAlgorithmSearchCV(VWClassifier(), \n",
    "                                       param_grid=params, \n",
    "                                       scoring='roc_auc', \n",
    "                                       verbose=True, \n",
    "                                       n_jobs=1, \n",
    "                                       population_size=5)\n",
    "start = time()\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Parameter search took %.2f seconds for %d generations of settings.\"\n",
    "      % (time() - start, search.generations_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperopt-sklearn\n",
    "https://github.com/hyperopt/hyperopt/wiki/FMin\n",
    "or maybe this (http://hyperopt.github.io/hyperopt-sklearn/) ???\n",
    "- Installation instructions: \n",
    "    - pip install hyperopt\n",
    "    - pip install pymongo\n",
    "    - pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter search took 10.78 seconds for 30 trials of settings.\n",
      "Best metric: 0.542935\n",
      "Best settings: {'power_t': [0.02073725005871313], 'l': [8.993703550092983]}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "X_a, X_b, y_a, y_b = train_test_split(X_train, y_train, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "param_names = ('power_t', 'l')\n",
    "space = (hp.uniform('power_t', 0, 1),\n",
    "         hp.uniform('l', 0.1, 10))\n",
    "\n",
    "def obj_func(params):\n",
    "    args = dict((k, params[i]) for i, k in enumerate(param_names))\n",
    "    model = VWClassifier(**args)\n",
    "    model.fit(X_a, y_a)\n",
    "    return 1 - metrics.roc_auc_score(y_b, model.predict(X_b))\n",
    "\n",
    "trials = Trials()\n",
    "max_evals = 30\n",
    "\n",
    "start = time()\n",
    "best = fmin(obj_func, \n",
    "            space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=max_evals, \n",
    "            trials=trials)\n",
    "\n",
    "print(\"Parameter search took %.2f seconds for %d trials of settings.\"\n",
    "      % (time() - start, max_evals))\n",
    "print \"Best metric: %f\" % (1. - trials.best_trial['result']['loss'])\n",
    "print \"Best settings: %s\" % trials.best_trial['misc']['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.555773226664\n"
     ]
    }
   ],
   "source": [
    "model = VWClassifier(power_t=0.02, l=9)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print 'AUC: {}'.format(metrics.roc_auc_score(y_tune, model.predict(X_tune)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
